{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0e5b30d027cd5d6551e0ca64586cec9434604c5c94347cd566128c059f6e75d28",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e5b30d027cd5d6551e0ca64586cec9434604c5c94347cd566128c059f6e75d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Conventional Feature Based QA System\n",
    "\n",
    "### Structure\n",
    "- import library\n",
    "- initialize data file path\n",
    "- functions of read dataset\n",
    "    - read MCTest dataset\n",
    "    - read DREAM dataset\n",
    "    - read RACE dataset\n",
    "- read dataset\n",
    "- functions of predicting answer\n",
    "    - get highest similarity choice\n",
    "    - word tokenization\n",
    "    - get synonyms of words\n",
    "- predict MC answer, of each question\n",
    "- predict MC answer, of whole dataset\n",
    "- main function (starting point)\n",
    "- analysis \n",
    "\n",
    "### Getting Started\n",
    "Install required python package\n",
    "Execute by Jupyter notebook compiler\n",
    "Set data file path, default path as:\n",
    "    /datasets/MCTest/MCTest/\n",
    "    /datasets/DREAM/\n",
    "    /datasets/RACE/RACE/\n",
    "Results of each dataset will be exported to:\n",
    "    /Stage 1 result/{dataset name}.csv\n",
    "\n",
    "### Package used\n",
    "python 3.8.6, os, json, itertools\n",
    "pandas 1.2.2, numpy 1.19.5, gensim 3.8.3, nltk 3.5\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import gensim       # for similarity\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet     # get synonyms\n",
    "from itertools import chain"
   ]
  },
  {
   "source": [
    "## Initialize data file path"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file path, dataset stored in \"/datasets\" in the script directory \n",
    "path = {\n",
    "    \"MC160\":{\n",
    "        \"Train\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc160.train.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc160.train.ans\")\n",
    "        },\n",
    "        \"Dev\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc160.dev.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc160.dev.ans\")\n",
    "        },\n",
    "        \"Test\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc160.test.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTestAnswers/mc160.test.ans\")\n",
    "        }\n",
    "    },\n",
    "    \"MC500\":{\n",
    "        \"Train\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc500.train.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc500.train.ans\")\n",
    "        },\n",
    "        \"Dev\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc500.dev.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc500.dev.ans\")\n",
    "        },\n",
    "        \"Test\":{\n",
    "            \"Question\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTest/mc500.test.tsv\"), \n",
    "            \"Answer\": os.path.join(sys.path[0], \"datasets\", \"MCTest/MCTestAnswers/mc500.test.ans\")\n",
    "        }\n",
    "    },\n",
    "    \"DREAM\":{\n",
    "        \"Train\": os.path.join(sys.path[0], \"datasets\", \"DREAM/train.json\"),\n",
    "        \"Dev\": os.path.join(sys.path[0], \"datasets\", \"DREAM/dev.json\"),\n",
    "        \"Test\": os.path.join(sys.path[0], \"datasets\", \"DREAM/test.json\")\n",
    "    },\n",
    "    \"RACE\":{\n",
    "        \"high\": {\n",
    "            \"Train\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/train/high\"),\n",
    "            \"Dev\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/dev/high\"),\n",
    "            \"Test\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/test/high\")\n",
    "        },\n",
    "        \"middle\": {\n",
    "            \"Train\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/train/middle\"),\n",
    "            \"Dev\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/dev/middle\"),\n",
    "            \"Test\": os.path.join(sys.path[0], \"datasets\", \"RACE/RACE/test/middle\")\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "source": [
    "## Read dataset file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMCTest(questionPath, answerPath):\n",
    "    question = pd.read_csv(questionPath,\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        names=[\"id\", \"properties\", \"article\",\n",
    "               \"q0\", \"q0_c0\", \"q0_c1\", \"q0_c2\", \"q0_c3\",\n",
    "               \"q1\", \"q1_c0\", \"q1_c1\", \"q1_c2\", \"q1_c3\",\n",
    "               \"q2\", \"q2_c0\", \"q2_c1\", \"q2_c2\", \"q2_c3\",\n",
    "               \"q3\", \"q3_c0\", \"q3_c1\", \"q3_c2\", \"q3_c3\",])\n",
    "    answer = pd.read_csv(answerPath,\n",
    "            sep='\\t',\n",
    "            header=None,\n",
    "            names=['q0_ans', 'q1_ans', 'q2_ans', 'q3_ans', ])\n",
    "\n",
    "    # pre-processing \n",
    "    dataset = []\n",
    "    for index, row in question.iterrows():\n",
    "        # for each story\n",
    "        for i in range(4):\n",
    "            # for each question\n",
    "            temp = {}\n",
    "            temp[\"article\"] = row[\"article\"].replace(\"\\\\newline\", \" \")  # remove \"\\newline\" char in article\n",
    "            temp[\"question\"] = row[f\"q{i}\"].split(\":\")[1]\n",
    "            temp[\"answer sentence type\"] = row[f\"q{i}\"].split(\":\")[0]\n",
    "            for j in range(4):\n",
    "                temp[f\"choice {j}\"] = row[f\"q{i}_c{j}\"]\n",
    "            \n",
    "            # answer choice = A/B/C/D, answer index = 0/1/2/3, answer = answer in string format\n",
    "            temp[\"answer choice\"] = answer.iloc[index][f\"q{i}_ans\"]\n",
    "            temp[\"answer index\"] = ord(temp[\"answer choice\"]) - 65      # from \"A\" to 0\n",
    "            temp[\"answer\"] = temp[\"choice {}\".format(ord(temp[\"answer choice\"]) - 65)]\n",
    "\n",
    "            dataset.append(temp)\n",
    "\n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDREAM(docPath):\n",
    "    with open(docPath) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    dataset = []\n",
    "    for story in data:\n",
    "        temp = {}\n",
    "\n",
    "        # pre-processing of article\n",
    "        # for sentence spoke by \"M:\", add prefix \"Men:\" to every sentence \n",
    "        # for sentence spoke by \"W:\", add prefix \"Women:\" to every sentence \n",
    "        temp[\"article\"] = \"\"\n",
    "        for sentence in story[0]:\n",
    "            if \"M:\" in sentence:\n",
    "                sentence = sentence.replace(\"M: \", \"\")\n",
    "                for sent in sent_tokenize(sentence):\n",
    "                    temp[\"article\"] += \"Men: \" + sent + \" \"\n",
    "            elif \"W:\" in sentence:\n",
    "                sentence = sentence.replace(\"W: \", \"\")\n",
    "                for sent in sent_tokenize(sentence):\n",
    "                    temp[\"article\"] += \"Woman: \" + sent + \" \"\n",
    "            else:\n",
    "                temp[\"article\"] += sentence\n",
    "\n",
    "        temp[\"question\"] = story[1][0][\"question\"]\n",
    "        for i in range(len(story[1][0][\"choice\"])):\n",
    "            temp[f\"choice {i}\"] = story[1][0][\"choice\"][i]\n",
    "\n",
    "        # answer choice = A/B/C/D, answer index = 0/1/2/3, answer = answer in string format\n",
    "        temp[\"answer\"] = story[1][0][\"answer\"]\n",
    "        for i in range(len(story[1][0][\"choice\"])):\n",
    "            if story[1][0][\"choice\"][i] == story[1][0][\"answer\"]:\n",
    "                temp[\"answer choice\"] = chr(i + 65)      # from 0 to \"A\"\n",
    "                temp[\"answer index\"] = i\n",
    "                break\n",
    "        \n",
    "        dataset.append(temp)\n",
    "\n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readRACE(docPath):\n",
    "    dataset = []\n",
    "\n",
    "    for filename in os.listdir(docPath):\n",
    "        with open(os.path.join(docPath, filename), 'r') as f: # open in readonly mode\n",
    "            story = json.load(f)\n",
    "        \n",
    "        temp = {}\n",
    "        temp[\"article\"] = story[\"article\"]\n",
    "\n",
    "        tempPerQuestion = {}\n",
    "        for i in range(len(story[\"questions\"])):\n",
    "            temp = {\"article\": temp[\"article\"]}   \n",
    "\n",
    "            temp[\"question\"] = story[\"questions\"][i]\n",
    "            for j in range(len(story[\"options\"][i])):\n",
    "                temp[f\"choice {j}\"] = story[\"options\"][i][j]\n",
    "                \n",
    "            # answer choice = A/B/C/D, answer index = 0/1/2/3, answer = answer in string format\n",
    "            temp[\"answer index\"] = ord(story[\"answers\"][i]) - 65      # from \"A\" to 0\n",
    "            temp[\"answer\"] = temp[f\"choice {temp['answer index']}\"]\n",
    "            temp[\"answer choice\"] = story[\"answers\"][i]\n",
    "\n",
    "            dataset.append(temp)\n",
    "\n",
    "    return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MC160 Dev\n(120, 10)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             article  \\\n",
       "0  It was Jessie Bear's birthday. She was having ...   \n",
       "1  It was Jessie Bear's birthday. She was having ...   \n",
       "\n",
       "                         question answer sentence type     choice 0 choice 1  \\\n",
       "0      Who was having a birthday?                  one  Jessie Bear   no one   \n",
       "1   Who didn't come to the party?             multiple         Lion    Tiger   \n",
       "\n",
       "  choice 2     choice 3 answer choice  answer index       answer  \n",
       "0     Lion        Tiger             A             0  Jessie Bear  \n",
       "1    Snake  Jessie Bear             C             2        Snake  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>question</th>\n      <th>answer sentence type</th>\n      <th>choice 0</th>\n      <th>choice 1</th>\n      <th>choice 2</th>\n      <th>choice 3</th>\n      <th>answer choice</th>\n      <th>answer index</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It was Jessie Bear's birthday. She was having ...</td>\n      <td>Who was having a birthday?</td>\n      <td>one</td>\n      <td>Jessie Bear</td>\n      <td>no one</td>\n      <td>Lion</td>\n      <td>Tiger</td>\n      <td>A</td>\n      <td>0</td>\n      <td>Jessie Bear</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It was Jessie Bear's birthday. She was having ...</td>\n      <td>Who didn't come to the party?</td>\n      <td>multiple</td>\n      <td>Lion</td>\n      <td>Tiger</td>\n      <td>Snake</td>\n      <td>Jessie Bear</td>\n      <td>C</td>\n      <td>2</td>\n      <td>Snake</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "def getDataset(dSet, purpose):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        dSet[String] = MC160 / MC500 / DREAM / RACE-middle / RACE-high\n",
    "        purpose[String] = Train / Test / Dev\n",
    "    Return:\n",
    "        dataset[pd.DataFrame]: dataset from selected data file\n",
    "    \"\"\"\n",
    "    print(\"{} {}\".format(dSet, purpose))\n",
    "    if dSet == \"MC160\" or dSet == \"MC500\":\n",
    "        pathQuestion = path[dSet][purpose][\"Question\"]\n",
    "        pathAnswer = path[dSet][purpose][\"Answer\"]\n",
    "\n",
    "        dataset = readMCTest(questionPath=pathQuestion, answerPath=pathAnswer)\n",
    "    elif dSet == \"DREAM\":\n",
    "        dataset = readDREAM(path[dSet][purpose])\n",
    "    elif dSet == \"RACE-high\":\n",
    "        dataset = readRACE(path[\"RACE\"][\"high\"][purpose])\n",
    "    elif dSet == \"RACE-middle\":\n",
    "        dataset = readRACE(path[\"RACE\"][\"middle\"][purpose])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# for quick view only\n",
    "dataset = getDataset(\"MC160\", \"Dev\")\n",
    "print(dataset.shape)\n",
    "dataset.head(2)"
   ]
  },
  {
   "source": [
    "## Sub function of getting prediction "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClosestSentence(choices, answerString):\n",
    "    \"\"\"\n",
    "    Find the highest similarity choice by a given query\n",
    "    Inputs:\n",
    "        choices[List]: list of sentences as document\n",
    "        answerString[String]: sentence as query\n",
    "    Return:\n",
    "        index[Int]: index of choice with highest similarity \n",
    "    \"\"\"\n",
    "    # for choices\n",
    "    gen_docs = []   # 1 item = 1 choice\n",
    "    \n",
    "    # word lemmatize, to lower case, and filter stopword of each choice\n",
    "    for choice in choices:\n",
    "        gen_docs.append([w.lower() for w in wordTokenize(choice)])\n",
    "    \n",
    "    # dictionary of choices, convert to BOW for each choice\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    \n",
    "    # build TFIDF model\n",
    "    tfidf = gensim.models.TfidfModel(corpus)\n",
    "\n",
    "    # build similarity model, using TFIDF of choices\n",
    "    sims = gensim.similarities.MatrixSimilarity(tfidf[corpus], num_features=len(dictionary))\n",
    "\n",
    "\n",
    "    # for answerString\n",
    "    # word lemmatize, to lower case, and filter stopword of each choice\n",
    "    tokenizedAnswer = wordTokenize(answerString.lower())\n",
    "\n",
    "    # convert to BOW\n",
    "    bowAnswer = dictionary.doc2bow(tokenizedAnswer)\n",
    "\n",
    "    # convert to TFIDF\n",
    "    tfidfAnswer = tfidf[bowAnswer]\n",
    "\n",
    "    # get similarity, select argmax, return closest sentence index\n",
    "    return np.argmax(sims[tfidfAnswer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "stopWords = set(stopwords.words(\"english\")) \n",
    "\n",
    "def wordTokenize(sentence):\n",
    "    \"\"\"\n",
    "    Word lemmatize, to lower case, and filter stopword of each choice\n",
    "    Input:\n",
    "        sentence[String]: a sentence\n",
    "    Return:\n",
    "        tokenized word[List]: list of tokenized word\n",
    "    \"\"\"\n",
    "    return [wnl.lemmatize(w.lower()) for w in word_tokenize(sentence) if w not in stopWords]\n",
    "        \n",
    "def getSynonyms(lemmatized):\n",
    "    \"\"\"\n",
    "    Getting sysnonyms of words by NLTK wordnet\n",
    "    Input:\n",
    "        lemmatized[List]: list of tokenized word\n",
    "    Return:\n",
    "        tempString[String]: joining all synonyms of all tokenized input word into one string\n",
    "    \"\"\"\n",
    "    tempString = \"\"\n",
    "    for word in lemmatized:\n",
    "        # get synonyms\n",
    "        synonyms = wordnet.synsets(word)\n",
    "        lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
    "        if lemmas:\n",
    "            # if word have synonyms\n",
    "            tempString += \" \".join(lemmas) + \" \"\n",
    "        else:\n",
    "            # if word doesn't have synonyms, e.g. wh-words, stopwords\n",
    "            tempString += \"\".join(word) + \" \"\n",
    "\n",
    "    return tempString"
   ]
  },
  {
   "source": [
    "## Main function of getting prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMC(article, question, options, answerSentenceType=\"\"):\n",
    "    \"\"\"\n",
    "    Predict answer of each question\n",
    "    Inputs:\n",
    "        article[String]\n",
    "        question[String]\n",
    "        options[List]: MC choices\n",
    "        answerSentenceType[String]: \"one\"/\"multiple\", only usable for MCTest\n",
    "    Return:\n",
    "        closestOption[Int]: predicted answer in index\n",
    "    \"\"\"\n",
    "    # article\n",
    "    sentences = sent_tokenize(article)      # from article to list of sentences\n",
    "    synonymsSentences = []\n",
    "    for sent in sentences:\n",
    "        lemmatizedSent = wordTokenize(sent)\n",
    "        synonymsSent = getSynonyms(lemmatizedSent)\n",
    "        if synonymsSent:\n",
    "            # if sentence has synonyms\n",
    "            synonymsSentences.append(synonymsSent)\n",
    "    \n",
    "    # question\n",
    "    lemmatizedQuestion = wordTokenize(question)\n",
    "    synonymsQuestion = getSynonyms(lemmatizedQuestion)\n",
    "\n",
    "    # get closest sentence(s) in article given the question\n",
    "    closestSentenceIndex = getClosestSentence(synonymsSentences, synonymsQuestion)\n",
    "    if (answerSentenceType == \"one\"):\n",
    "        # for MCTest, only get 1 sentence if answer sentence type = \"one\"\n",
    "        closestSentence = synonymsSentences[closestSentenceIndex]\n",
    "    else:\n",
    "        # get 2 sentences before and after and the closest sentence\n",
    "        closestSentence = synonymsSentences[max(closestSentenceIndex - 2, 0)]\n",
    "        closestSentence += synonymsSentences[max(closestSentenceIndex - 1, 0)]\n",
    "        closestSentence += synonymsSentences[closestSentenceIndex]\n",
    "        closestSentence += synonymsSentences[min(closestSentenceIndex + 1, len(synonymsSentences)-1)]\n",
    "        closestSentence += synonymsSentences[min(closestSentenceIndex + 2, len(synonymsSentences)-1)]\n",
    "    \n",
    "    # options\n",
    "    synonymsOptions = []\n",
    "    for option in options:\n",
    "        # for each option\n",
    "        tempLemmatizedOption = wordTokenize(option)\n",
    "        tempSynonymsOption = getSynonyms(tempLemmatizedOption)\n",
    "        synonymsOptions.append(tempSynonymsOption)\n",
    "\n",
    "    # get closest answer in choices given the closest sentence(s) in article\n",
    "    closestOption = getClosestSentence(synonymsOptions, closestSentence)\n",
    "    \n",
    "    return closestOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset):\n",
    "    \"\"\"\n",
    "    Predict answer of whole dataset\n",
    "    Input:\n",
    "        dataset[pd.DataFrame]\n",
    "    Return:\n",
    "        accuracy info.[Dict]\n",
    "        dataset[pd.DataFrame]: with the predicted answer as new column \n",
    "    \"\"\"\n",
    "    # foc accuracy calculation purpose\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    wrong = 0\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        # for each question\n",
    "\n",
    "        # get MC options of question\n",
    "        options = row[dataset.columns[dataset.columns.str.startswith('choice')]].tolist()\n",
    "\n",
    "        # predict answer by article, question, choices\n",
    "        if \"answer sentence type\" in row:\n",
    "            # for MCTest\n",
    "            predictedAnswer = predictMC(row[\"article\"], row[\"question\"], options, row[\"answer sentence type\"])\n",
    "        else:\n",
    "            # for non MCTest\n",
    "            predictedAnswer = predictMC(row[\"article\"], row[\"question\"], options)\n",
    "\n",
    "        # concate predicted answer to dataset\n",
    "        dataset.loc[index,'predicted answer'] = predictedAnswer\n",
    "\n",
    "        # for accuracy calculation purpose\n",
    "        if(row[\"answer index\"] == predictedAnswer):\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "        count += 1\n",
    "        \n",
    "        # for executing information\n",
    "        if count % 100 == 0:\n",
    "            print(f\"correct= {correct}  wrong= {wrong}  count= {count}  accuracy= {correct/count}\")\n",
    "    # for executing information\n",
    "    print(f\"correct= {correct}  wrong= {wrong}  count= {count}  accuracy= {correct/count}\")\n",
    "\n",
    "    return {\"correct\":correct, \"wrong\":wrong, \"count\":count, \"accuracy\": correct/count}, dataset\n"
   ]
  },
  {
   "source": [
    "## Main function (starting point)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MC160 Test\n",
      "correct= 48  wrong= 52  count= 100  accuracy= 0.48\n",
      "correct= 111  wrong= 89  count= 200  accuracy= 0.555\n",
      "correct= 131  wrong= 109  count= 240  accuracy= 0.5458333333333333\n",
      "MC500 Test\n",
      "correct= 53  wrong= 47  count= 100  accuracy= 0.53\n",
      "correct= 102  wrong= 98  count= 200  accuracy= 0.51\n",
      "correct= 153  wrong= 147  count= 300  accuracy= 0.51\n",
      "correct= 203  wrong= 197  count= 400  accuracy= 0.5075\n",
      "correct= 249  wrong= 251  count= 500  accuracy= 0.498\n",
      "correct= 307  wrong= 293  count= 600  accuracy= 0.5116666666666667\n",
      "correct= 307  wrong= 293  count= 600  accuracy= 0.5116666666666667\n",
      "DREAM Test\n",
      "correct= 30  wrong= 70  count= 100  accuracy= 0.3\n",
      "correct= 61  wrong= 139  count= 200  accuracy= 0.305\n",
      "correct= 95  wrong= 205  count= 300  accuracy= 0.31666666666666665\n",
      "correct= 142  wrong= 258  count= 400  accuracy= 0.355\n",
      "correct= 178  wrong= 322  count= 500  accuracy= 0.356\n",
      "correct= 225  wrong= 375  count= 600  accuracy= 0.375\n",
      "correct= 274  wrong= 426  count= 700  accuracy= 0.3914285714285714\n",
      "correct= 313  wrong= 487  count= 800  accuracy= 0.39125\n",
      "correct= 354  wrong= 546  count= 900  accuracy= 0.3933333333333333\n",
      "correct= 391  wrong= 609  count= 1000  accuracy= 0.391\n",
      "correct= 426  wrong= 674  count= 1100  accuracy= 0.38727272727272727\n",
      "correct= 475  wrong= 725  count= 1200  accuracy= 0.3958333333333333\n",
      "correct= 506  wrong= 781  count= 1287  accuracy= 0.39316239316239315\n",
      "RACE-middle Test\n",
      "correct= 37  wrong= 63  count= 100  accuracy= 0.37\n",
      "correct= 77  wrong= 123  count= 200  accuracy= 0.385\n",
      "correct= 114  wrong= 186  count= 300  accuracy= 0.38\n",
      "correct= 147  wrong= 253  count= 400  accuracy= 0.3675\n",
      "correct= 181  wrong= 319  count= 500  accuracy= 0.362\n",
      "correct= 219  wrong= 381  count= 600  accuracy= 0.365\n",
      "correct= 256  wrong= 444  count= 700  accuracy= 0.3657142857142857\n",
      "correct= 304  wrong= 496  count= 800  accuracy= 0.38\n",
      "correct= 338  wrong= 562  count= 900  accuracy= 0.37555555555555553\n",
      "correct= 381  wrong= 619  count= 1000  accuracy= 0.381\n",
      "correct= 410  wrong= 690  count= 1100  accuracy= 0.37272727272727274\n",
      "correct= 445  wrong= 755  count= 1200  accuracy= 0.37083333333333335\n",
      "correct= 473  wrong= 827  count= 1300  accuracy= 0.3638461538461538\n",
      "correct= 511  wrong= 889  count= 1400  accuracy= 0.365\n",
      "correct= 520  wrong= 916  count= 1436  accuracy= 0.362116991643454\n",
      "RACE-high Test\n",
      "correct= 29  wrong= 71  count= 100  accuracy= 0.29\n",
      "correct= 68  wrong= 132  count= 200  accuracy= 0.34\n",
      "correct= 98  wrong= 202  count= 300  accuracy= 0.32666666666666666\n",
      "correct= 125  wrong= 275  count= 400  accuracy= 0.3125\n",
      "correct= 157  wrong= 343  count= 500  accuracy= 0.314\n",
      "correct= 185  wrong= 415  count= 600  accuracy= 0.30833333333333335\n",
      "correct= 219  wrong= 481  count= 700  accuracy= 0.31285714285714283\n",
      "correct= 246  wrong= 554  count= 800  accuracy= 0.3075\n",
      "correct= 269  wrong= 631  count= 900  accuracy= 0.29888888888888887\n",
      "correct= 295  wrong= 705  count= 1000  accuracy= 0.295\n",
      "correct= 327  wrong= 773  count= 1100  accuracy= 0.2972727272727273\n",
      "correct= 361  wrong= 839  count= 1200  accuracy= 0.30083333333333334\n",
      "correct= 392  wrong= 908  count= 1300  accuracy= 0.30153846153846153\n",
      "correct= 416  wrong= 984  count= 1400  accuracy= 0.29714285714285715\n",
      "correct= 443  wrong= 1057  count= 1500  accuracy= 0.29533333333333334\n",
      "correct= 477  wrong= 1123  count= 1600  accuracy= 0.298125\n",
      "correct= 506  wrong= 1194  count= 1700  accuracy= 0.29764705882352943\n",
      "correct= 536  wrong= 1264  count= 1800  accuracy= 0.29777777777777775\n",
      "correct= 560  wrong= 1340  count= 1900  accuracy= 0.29473684210526313\n",
      "correct= 590  wrong= 1410  count= 2000  accuracy= 0.295\n",
      "correct= 621  wrong= 1479  count= 2100  accuracy= 0.2957142857142857\n",
      "correct= 653  wrong= 1547  count= 2200  accuracy= 0.2968181818181818\n",
      "correct= 688  wrong= 1612  count= 2300  accuracy= 0.2991304347826087\n",
      "correct= 718  wrong= 1682  count= 2400  accuracy= 0.2991666666666667\n",
      "correct= 749  wrong= 1751  count= 2500  accuracy= 0.2996\n",
      "correct= 780  wrong= 1820  count= 2600  accuracy= 0.3\n",
      "correct= 808  wrong= 1892  count= 2700  accuracy= 0.2992592592592593\n",
      "correct= 840  wrong= 1960  count= 2800  accuracy= 0.3\n",
      "correct= 876  wrong= 2024  count= 2900  accuracy= 0.3020689655172414\n",
      "correct= 911  wrong= 2089  count= 3000  accuracy= 0.30366666666666664\n",
      "correct= 942  wrong= 2158  count= 3100  accuracy= 0.3038709677419355\n",
      "correct= 974  wrong= 2226  count= 3200  accuracy= 0.304375\n",
      "correct= 1007  wrong= 2293  count= 3300  accuracy= 0.3051515151515152\n",
      "correct= 1046  wrong= 2354  count= 3400  accuracy= 0.3076470588235294\n",
      "correct= 1078  wrong= 2420  count= 3498  accuracy= 0.3081761006289308\n"
     ]
    }
   ],
   "source": [
    "# define dataset \n",
    "purpose = \"Train\"\n",
    "purpose = \"Dev\"\n",
    "purpose = \"Test\"\n",
    "\n",
    "dSetList = [\"MC160\", \"MC500\", \"DREAM\", \"RACE-middle\", \"RACE-high\"]\n",
    "\n",
    "accuracy = []\n",
    "dataset = {}\n",
    "\n",
    "for dSet in dSetList:\n",
    "    temp = []\n",
    "    dataset[dSet] = getDataset(dSet, purpose)\n",
    "    temp, dataset[dSet] = predict(dataset[dSet])\n",
    "    temp[\"dSet\"] = dSet\n",
    "    temp[\"purpose\"] = purpose\n",
    "    accuracy.append(temp)"
   ]
  },
  {
   "source": [
    "## Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     correct  wrong  count  accuracy\n",
       "dSet        purpose                                 \n",
       "MC160       Test         131    109    240  0.545833\n",
       "MC500       Test         307    293    600  0.511667\n",
       "DREAM       Test         506    781   1287  0.393162\n",
       "RACE-middle Test         520    916   1436  0.362117\n",
       "RACE-high   Test        1078   2420   3498  0.308176"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>correct</th>\n      <th>wrong</th>\n      <th>count</th>\n      <th>accuracy</th>\n    </tr>\n    <tr>\n      <th>dSet</th>\n      <th>purpose</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MC160</th>\n      <th>Test</th>\n      <td>131</td>\n      <td>109</td>\n      <td>240</td>\n      <td>0.545833</td>\n    </tr>\n    <tr>\n      <th>MC500</th>\n      <th>Test</th>\n      <td>307</td>\n      <td>293</td>\n      <td>600</td>\n      <td>0.511667</td>\n    </tr>\n    <tr>\n      <th>DREAM</th>\n      <th>Test</th>\n      <td>506</td>\n      <td>781</td>\n      <td>1287</td>\n      <td>0.393162</td>\n    </tr>\n    <tr>\n      <th>RACE-middle</th>\n      <th>Test</th>\n      <td>520</td>\n      <td>916</td>\n      <td>1436</td>\n      <td>0.362117</td>\n    </tr>\n    <tr>\n      <th>RACE-high</th>\n      <th>Test</th>\n      <td>1078</td>\n      <td>2420</td>\n      <td>3498</td>\n      <td>0.308176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# performance\n",
    "pd.DataFrame(accuracy).set_index([\"dSet\", \"purpose\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export result to csv\n",
    "for ds in dataset:\n",
    "    dataset[ds].to_csv(f\"Stage 1 result/{ds}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      article  question  choice 0  choice 1  choice 2  \\\n",
       "answer sentence type                                                    \n",
       "multiple                  152       152       152       152       152   \n",
       "one                       155       155       155       155       155   \n",
       "\n",
       "                      choice 3  answer choice  answer index  answer  \\\n",
       "answer sentence type                                                  \n",
       "multiple                   152            152           152     152   \n",
       "one                        155            155           155     155   \n",
       "\n",
       "                      predicted answer  \n",
       "answer sentence type                    \n",
       "multiple                           152  \n",
       "one                                155  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>question</th>\n      <th>choice 0</th>\n      <th>choice 1</th>\n      <th>choice 2</th>\n      <th>choice 3</th>\n      <th>answer choice</th>\n      <th>answer index</th>\n      <th>answer</th>\n      <th>predicted answer</th>\n    </tr>\n    <tr>\n      <th>answer sentence type</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>multiple</th>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>one</th>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n      <td>155</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# for MCTest only\n",
    "dataset[\"MC500\"][dataset[\"MC500\"][\"answer index\"] != dataset[\"MC500\"][\"predicted answer\"]].groupby([\"answer sentence type\"]).count()\n",
    "\n",
    "dataset[\"MC500\"][dataset[\"MC500\"][\"answer index\"] == dataset[\"MC500\"][\"predicted answer\"]].groupby([\"answer sentence type\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               article  \\\n",
       "0    It was Sally's birthday. She was very excited....   \n",
       "1    It was Sally's birthday. She was very excited....   \n",
       "2    It was Sally's birthday. She was very excited....   \n",
       "3    It was Sally's birthday. She was very excited....   \n",
       "4    On the farm there was a little piggy named And...   \n",
       "..                                                 ...   \n",
       "595  Greg and his mother were building a racing car...   \n",
       "596  Joey went to a baseball game during the winter...   \n",
       "597  Joey went to a baseball game during the winter...   \n",
       "598  Joey went to a baseball game during the winter...   \n",
       "599  Joey went to a baseball game during the winter...   \n",
       "\n",
       "                                              question answer sentence type  \\\n",
       "0                       What time did the party start?                  one   \n",
       "1                           Who got hurt at the party?             multiple   \n",
       "2                                Whose birthday is it?                  one   \n",
       "3          What time did Jennifer arrive to the party?             multiple   \n",
       "4     What did the piggies do when Andy got back fr...             multiple   \n",
       "..                                                 ...                  ...   \n",
       "595                      Where was the race happening?             multiple   \n",
       "596   Who went to the baseball game and with how ma...             multiple   \n",
       "597             what kind of store did Joey turn into?                  one   \n",
       "598   Which team won the game Joey went to and by h...             multiple   \n",
       "599                      What dessert did Joey choose?                  one   \n",
       "\n",
       "                        choice 0                           choice 1  \\\n",
       "0                             10                                  2   \n",
       "1              Erin and Jennifer                     Cathy and Erin   \n",
       "2                          Cathy                            Jessica   \n",
       "3                              1                                  2   \n",
       "4      play games and eat dinner  play in the mud and go for a walk   \n",
       "..                           ...                                ...   \n",
       "595                 At the park.      On the track near his school.   \n",
       "596                Joey, nobody.                       Mark, nobody   \n",
       "597                 Garden store                      Grocery store   \n",
       "598      Home team, by two runs.              Away team, by one run   \n",
       "599  warm brownie with ice cream                      Vanilla shake   \n",
       "\n",
       "                             choice 2                           choice 3  \\\n",
       "0                                  11                                  1   \n",
       "1                  Jennifer and Sally                     Erin and Sally   \n",
       "2                               Sally                           Jennifer   \n",
       "3                                   8                                 10   \n",
       "4    swim in the river and play games  go for a walk and look at flowers   \n",
       "..                                ...                                ...   \n",
       "595                       In a river.                 In their backyard.   \n",
       "596                   Sam, two others                Joey, three others.   \n",
       "597                         Car store                       Coffee store   \n",
       "598           Away team, by two runs.             Home team, by one run.   \n",
       "599          apple pie with ice cream     Marshmallow and chocolate cake   \n",
       "\n",
       "    answer choice  answer index                          answer  \\\n",
       "0               D             3                               1   \n",
       "1               C             2              Jennifer and Sally   \n",
       "2               C             2                           Sally   \n",
       "3               B             1                               2   \n",
       "4               A             0       play games and eat dinner   \n",
       "..            ...           ...                             ...   \n",
       "595             B             1   On the track near his school.   \n",
       "596             A             0                   Joey, nobody.   \n",
       "597             D             3                    Coffee store   \n",
       "598             D             3          Home team, by one run.   \n",
       "599             D             3  Marshmallow and chocolate cake   \n",
       "\n",
       "     predicted answer  \n",
       "0                 0.0  \n",
       "1                 3.0  \n",
       "2                 2.0  \n",
       "3                 0.0  \n",
       "4                 3.0  \n",
       "..                ...  \n",
       "595               1.0  \n",
       "596               1.0  \n",
       "597               3.0  \n",
       "598               3.0  \n",
       "599               0.0  \n",
       "\n",
       "[600 rows x 11 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>article</th>\n      <th>question</th>\n      <th>answer sentence type</th>\n      <th>choice 0</th>\n      <th>choice 1</th>\n      <th>choice 2</th>\n      <th>choice 3</th>\n      <th>answer choice</th>\n      <th>answer index</th>\n      <th>answer</th>\n      <th>predicted answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>It was Sally's birthday. She was very excited....</td>\n      <td>What time did the party start?</td>\n      <td>one</td>\n      <td>10</td>\n      <td>2</td>\n      <td>11</td>\n      <td>1</td>\n      <td>D</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>It was Sally's birthday. She was very excited....</td>\n      <td>Who got hurt at the party?</td>\n      <td>multiple</td>\n      <td>Erin and Jennifer</td>\n      <td>Cathy and Erin</td>\n      <td>Jennifer and Sally</td>\n      <td>Erin and Sally</td>\n      <td>C</td>\n      <td>2</td>\n      <td>Jennifer and Sally</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>It was Sally's birthday. She was very excited....</td>\n      <td>Whose birthday is it?</td>\n      <td>one</td>\n      <td>Cathy</td>\n      <td>Jessica</td>\n      <td>Sally</td>\n      <td>Jennifer</td>\n      <td>C</td>\n      <td>2</td>\n      <td>Sally</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>It was Sally's birthday. She was very excited....</td>\n      <td>What time did Jennifer arrive to the party?</td>\n      <td>multiple</td>\n      <td>1</td>\n      <td>2</td>\n      <td>8</td>\n      <td>10</td>\n      <td>B</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>On the farm there was a little piggy named And...</td>\n      <td>What did the piggies do when Andy got back fr...</td>\n      <td>multiple</td>\n      <td>play games and eat dinner</td>\n      <td>play in the mud and go for a walk</td>\n      <td>swim in the river and play games</td>\n      <td>go for a walk and look at flowers</td>\n      <td>A</td>\n      <td>0</td>\n      <td>play games and eat dinner</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>595</th>\n      <td>Greg and his mother were building a racing car...</td>\n      <td>Where was the race happening?</td>\n      <td>multiple</td>\n      <td>At the park.</td>\n      <td>On the track near his school.</td>\n      <td>In a river.</td>\n      <td>In their backyard.</td>\n      <td>B</td>\n      <td>1</td>\n      <td>On the track near his school.</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>596</th>\n      <td>Joey went to a baseball game during the winter...</td>\n      <td>Who went to the baseball game and with how ma...</td>\n      <td>multiple</td>\n      <td>Joey, nobody.</td>\n      <td>Mark, nobody</td>\n      <td>Sam, two others</td>\n      <td>Joey, three others.</td>\n      <td>A</td>\n      <td>0</td>\n      <td>Joey, nobody.</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>Joey went to a baseball game during the winter...</td>\n      <td>what kind of store did Joey turn into?</td>\n      <td>one</td>\n      <td>Garden store</td>\n      <td>Grocery store</td>\n      <td>Car store</td>\n      <td>Coffee store</td>\n      <td>D</td>\n      <td>3</td>\n      <td>Coffee store</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>Joey went to a baseball game during the winter...</td>\n      <td>Which team won the game Joey went to and by h...</td>\n      <td>multiple</td>\n      <td>Home team, by two runs.</td>\n      <td>Away team, by one run</td>\n      <td>Away team, by two runs.</td>\n      <td>Home team, by one run.</td>\n      <td>D</td>\n      <td>3</td>\n      <td>Home team, by one run.</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>599</th>\n      <td>Joey went to a baseball game during the winter...</td>\n      <td>What dessert did Joey choose?</td>\n      <td>one</td>\n      <td>warm brownie with ice cream</td>\n      <td>Vanilla shake</td>\n      <td>apple pie with ice cream</td>\n      <td>Marshmallow and chocolate cake</td>\n      <td>D</td>\n      <td>3</td>\n      <td>Marshmallow and chocolate cake</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows Ã— 11 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "dataset[\"MC500\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}